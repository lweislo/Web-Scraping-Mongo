{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # Mac-specific browser init\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    return browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_news():\n",
    "    browser = init_browser()\n",
    "    # Gather the latest Mars news from NASA\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "    time.sleep(1)\n",
    "    # Scrape the page\n",
    "    soup = BeautifulSoup(browser.html, 'lxml')\n",
    "    browser.quit()\n",
    "    headline_list = [] # Store the headlines\n",
    "\n",
    "    # News articles are in a div tag class list_text\n",
    "    article = soup.find_all('div', class_='list_text')\n",
    "    \n",
    "    # Loop through returned results\n",
    "    for item in article:\n",
    "        list_dict = {}\n",
    "        # Error handling\n",
    "        try:\n",
    "            # Grab the headline\n",
    "            headline = item.find('a').get_text()\n",
    "            # Grab the strapline\n",
    "            strapline = item.find('div', class_='article_teaser_body').get_text()\n",
    "            # Append to the lists\n",
    "            if (headline and strapline):\n",
    "                list_dict['headline'] = headline\n",
    "                list_dict['strapline'] = strapline\n",
    "                # Put the headline and strapline in a list\n",
    "                headline_list.append(list_dict)\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        except ElementDoesNotExist as e:\n",
    "            print(e)\n",
    "    return headline_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_news()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_image():\n",
    "    output_dict = {}\n",
    "    browser = init_browser()\n",
    "# Visit the JPL site \n",
    "    image_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    base_url = image_url.split('/spaceimages')[0]\n",
    "    browser.visit(image_url)\n",
    "\n",
    "    # Click to expand fancybox and get the full image\n",
    "    try:\n",
    "        browser.click_link_by_partial_text('FULL IMAGE')\n",
    "        time.sleep(3)\n",
    "    # Scrape out the image link\n",
    "        soup2 = BeautifulSoup(browser.html, 'lxml')\n",
    "        browser.quit()\n",
    "    except ElementDoesNotExist:\n",
    "        print(\"Error with featured image\")\n",
    "        browser.quit()\n",
    "\n",
    "    try:\n",
    "        image_tag = soup2.find('img', class_='fancybox-image')\n",
    "        image_title = soup2.find('div', class_='fancybox-title').text\n",
    "        image_rel_url = image_tag['src']\n",
    "    #Put together a functional URL\n",
    "        featured_image_url = base_url + image_rel_url\n",
    "        output_dict['img_url'] = featured_image_url\n",
    "        output_dict['title'] = image_title.split('more info')[0].rstrip()\n",
    "        output_dict['type'] = 'featured'\n",
    "        return output_dict\n",
    "    except ElementDoesNotExist:\n",
    "        print(\"Error with featured image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA18884_ip.jpg',\n",
       " 'title': \"Work on NASA's InSight Lander Starts New Phase\",\n",
       " 'type': 'featured'}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_weather():\n",
    "    output_dict = {}\n",
    "#     browser = init_browser()\n",
    "# Visit the Mars Weather Twitter page\n",
    "    twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "#     browser.visit(twitter_url)\n",
    "#     html = browser.html\n",
    "    response = requests.get(twitter_url)\n",
    "    # Scrape out some tweets\n",
    "    soup3 = BeautifulSoup(response.text, 'lxml')\n",
    "    try:\n",
    "        tweets = soup3.find_all('div', class_='js-tweet-text-container', limit=10)\n",
    "#         browser.quit()\n",
    "    except AttributeError:\n",
    "        print(\"Error with tweet\")\n",
    "#         browser.quit()\n",
    "    # To get around potential retweets,\n",
    "    # go through the top 10 tweets and find one that looks like weather\n",
    "    for item in tweets:\n",
    "        if item.p.text.split(' ')[0] == 'Sol':\n",
    "            mars_weather = item.p.text.split('pic.twitter')[0]\n",
    "            mars_weather = mars_weather.split(',')\n",
    "            output_dict['date'] = mars_weather[0]\n",
    "            output_dict['high_temp'] = mars_weather[1].split('high ')[1]\n",
    "            output_dict['low_temp'] = mars_weather[2].split('low ')[1]\n",
    "            output_dict['pressure'] = mars_weather[3].split('pressure at ')[1]\n",
    "            output_dict['daylight'] = mars_weather[4].split('daylight ')[1]\n",
    "            return output_dict\n",
    "            # Exit the loop if one is found that looks like weather\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'Sol 2319 (2019-02-13)',\n",
       " 'high_temp': '-17C/1F',\n",
       " 'low_temp': '-72C/-97F',\n",
       " 'pressure': '8.12 hPa',\n",
       " 'daylight': '06:46-18:52'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_facts():\n",
    "    output_dict={}\n",
    "# Visit the Mars Space Facts page\n",
    "    try:\n",
    "        facts_url = 'http://space-facts.com/mars/'\n",
    "        tables = pd.read_html(facts_url)\n",
    "        df = tables[0]\n",
    "        df.columns=['fact','data']\n",
    "        df.set_index('fact')\n",
    "        facts_table = df.to_html()\n",
    "        output_dict['facts_table'] = facts_table\n",
    "        return output_dict\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facts_table': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>fact</th>\\n      <th>data</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_facts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_hemispheres():\n",
    "# A blank list for the image name and URLS\n",
    "    hemisphere_image_urls = []\n",
    "# Open a browser\n",
    "    browser = init_browser()\n",
    "# Get the results from Mars Hemispheres image search and store in results\n",
    "    h_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    base_url = h_url.split('/search')[0]\n",
    "    # Navigate to the page\n",
    "    browser.visit(h_url)\n",
    "# Store the html in the soup\n",
    "    soup4 = BeautifulSoup(browser.html, 'html.parser')\n",
    "# Parse out the desired content    \n",
    "    try:\n",
    "        results = soup4.find_all('div', class_='description')\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "\n",
    "    # Iterate through the soup results and store the information as a list of dictionaries\n",
    "    for item in results:\n",
    "        link_dict = {} # A blank temporary dictionary for each iteration\n",
    "        # Get the URL from the a-tag\n",
    "        link = base_url + item.find('a')['href']\n",
    "#         print(link)\n",
    "        # Visit each link in the results to get full image information\n",
    "        browser.visit(link)\n",
    "#         print('trying page')\n",
    "        time.sleep(1)\n",
    "\n",
    "        #Now scrape the page looking for the jpg image with text 'Sample'\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "            img_list = soup.find('a', text='Sample')\n",
    "        # Storing the data in the dictionary \n",
    "            link_dict['title'] = soup.find('h2', class_='title').text\n",
    "            link_dict['img_url'] = img_list['href']\n",
    "            link_dict['type'] = 'hemisphere'\n",
    "            # Appending dictionary to the list for output\n",
    "            hemisphere_image_urls.append(link_dict)\n",
    "        except ElementDoesNotExist:\n",
    "            print(\"Error with featured image\")\n",
    "\n",
    "    browser.quit()\n",
    "    return hemisphere_image_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg',\n",
       "  'type': 'hemisphere'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg',\n",
       "  'type': 'hemisphere'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg',\n",
       "  'type': 'hemisphere'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg',\n",
       "  'type': 'hemisphere'}]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_hemispheres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
